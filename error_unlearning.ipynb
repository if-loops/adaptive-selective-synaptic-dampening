{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "from typing import Dict, List\n",
    "from torch.utils.data import DataLoader\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# import TPE sampler\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Hiding the warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the general parameters here\n",
    "\n",
    "# Can be used if run iteratively but should be avoided\n",
    "SKIP_OPTUNA = False\n",
    "SKIP_DATA_LOADING = False\n",
    "\n",
    "\n",
    "N_TRIALS = 10\n",
    "TEST_PERCENTAGE = 20 # [1, 100]\n",
    "\n",
    "gamma_ = 0.95\n",
    "\n",
    "FOLDER_PREFIX = \"small\" # reference to model size for identification and plots\n",
    "\n",
    "CLASSES = 3\n",
    "\n",
    "# Placeholders\n",
    "MISTAKE_PERCENTAGE = 0 # for the NN param search\n",
    "ALPHA = \"Placeholder\"\n",
    "LAMBDA_PARAM = \"Placeholder\"\n",
    "DAMPEN_LIMIT = \"Placeholder\"\n",
    "TOLERANCE = \"Placeholder\"\n",
    "PERCENTILE =\"Placeholder\"\n",
    "ERROR_SCENARIO = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All functions go here\n",
    "\n",
    "# set random seeds for random, numpy and torch\n",
    "SEED = 42\n",
    "BATCHSIZE = 1024\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "sampler = TPESampler(seed=SEED)  # Make the sampler behave in a deterministic way.\n",
    "\n",
    "\n",
    "def convert_boolean_to_int(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == bool:\n",
    "            df[column] = df[column].astype(int)\n",
    "    return df\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units, and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 3, 3, step=1)\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    in_features = X_train.shape[1]  # Input feature size based on X_train\n",
    "\n",
    "    out_features = trial.suggest_int(\"n_units\", 100, 100, step=50)\n",
    "\n",
    "    for i in range(int(n_layers)):\n",
    "\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.BatchNorm1d(out_features))  # Add BatchNorm1d layer\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def get_custom_dataset(X, y):\n",
    "    # Convert the dataframes to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "    custom_dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    data_loader = torch.utils.data.DataLoader(custom_dataset, batch_size=BATCHSIZE, shuffle=False)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    global model\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    l2_pen = trial.suggest_float(\"l2_pen\", 1e-6, 1e-1, log=True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=l2_pen)\n",
    "\n",
    "    EPOCHS = trial.suggest_int(\"epochs\", 25, 25, step=5)\n",
    "\n",
    "    # Get the custom dataset.\n",
    "    # split X_train and y_train_class into train and validation sets\n",
    "    X_Train, X_Val, y_Train_class, y_Val_class = train_test_split(X_train, y_train_class, test_size=0.2, random_state=42) # CHANGED\n",
    "\n",
    "    train_loader = get_custom_dataset(X_Train, y_Train_class)\n",
    "    valid_loader = get_custom_dataset(X_Val, y_Val_class)\n",
    "\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma_)\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def callback(study, trial):\n",
    "    global best_model\n",
    "    if study.best_trial == trial:\n",
    "        best_model = model\n",
    "\n",
    "class ParameterPerturber:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        opt,\n",
    "        device,\n",
    "        parameters,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.opt = opt\n",
    "        self.device = \"mps\"\n",
    "        self.alpha = parameters[\"selection_weighting\"]\n",
    "        self.xmin = None\n",
    "        self.device = device\n",
    "\n",
    "        self.lower_bound = 1\n",
    "        self.exponent = 1\n",
    "        self.magnitude_diff = None  # unused\n",
    "        self.min_layer = -1\n",
    "        self.max_layer = -1\n",
    "        self.forget_threshold = 1  # unused\n",
    "        self.dampening_constant = parameters[\"dampening_constant\"]\n",
    "        self.selection_weighting = parameters[\"selection_weighting\"]\n",
    "\n",
    "    def get_layer_num(self, layer_name: str) -> int:\n",
    "        layer_id = layer_name.split(\".\")[1]\n",
    "        if layer_id.isnumeric():\n",
    "            return int(layer_id)\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def zerolike_params_dict(self, model: torch.nn) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Taken from: Avalanche: an End-to-End Library for Continual Learning - https://github.com/ContinualAI/avalanche\n",
    "        Returns a dict like named_parameters(), with zeroed-out parameter valuse\n",
    "        Parameters:\n",
    "        model (torch.nn): model to get param dict from\n",
    "        Returns:\n",
    "        dict(str,torch.Tensor): dict of zero-like params\n",
    "        \"\"\"\n",
    "        return dict(\n",
    "            [\n",
    "                (k, torch.zeros_like(p, device=p.device))\n",
    "                for k, p in model.named_parameters()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def calc_importance(self, dataloader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Adapated from: Avalanche: an End-to-End Library for Continual Learning - https://github.com/ContinualAI/avalanche\n",
    "        Calculate per-parameter, importance\n",
    "            returns a dictionary [param_name: list(importance per parameter)]\n",
    "        Parameters:\n",
    "        DataLoader (DataLoader): DataLoader to be iterated over\n",
    "        Returns:\n",
    "        importances (dict(str, torch.Tensor([]))): named_parameters-like dictionary containing list of importances for each parameter\n",
    "        \"\"\"\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        importances = self.zerolike_params_dict(self.model)\n",
    "        for batch in dataloader:\n",
    "            # This is hardcoded to the keys; change for other applications\n",
    "            x, y = batch\n",
    "\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.opt.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "\n",
    "            for (k1, p), (k2, imp) in zip(\n",
    "                self.model.named_parameters(), importances.items()\n",
    "            ):\n",
    "                if p.grad is not None:\n",
    "                    imp.data += p.grad.data.clone().pow(2)\n",
    "                    # imp.data = torch.max(p.grad.data.clone().pow(2), imp.data)\n",
    "\n",
    "        # average over mini batch length\n",
    "        for _, imp in importances.items():\n",
    "            imp.data /= float(len(dataloader))\n",
    "\n",
    "        return importances\n",
    "\n",
    "    def modify_weight(\n",
    "        self,\n",
    "        original_importance: List[Dict[str, torch.Tensor]],\n",
    "        forget_importance: List[Dict[str, torch.Tensor]],\n",
    "        PERCENTILE = \"XXXX\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Perturb weights based on the SSD equations given in the paper\n",
    "        Parameters:\n",
    "        original_importance (List[Dict[str, torch.Tensor]]): list of importances for original dataset\n",
    "        forget_importance (List[Dict[str, torch.Tensor]]): list of importances for forget sample\n",
    "        threshold (float): value to multiply original imp by to determine memorization.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        rel_list = list()\n",
    "\n",
    "        # Get the indices of the fully connected layers\n",
    "        fully_connected_layer_indices = list()\n",
    "        for idx, layer in enumerate(self.model.children()):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                fully_connected_layer_indices.append(idx+1)\n",
    "        \n",
    "        print(\"LAYERS: \",fully_connected_layer_indices)\n",
    "\n",
    "        num_layers = sum(1 for name, layer in self.model.named_children())\n",
    "\n",
    "        if True:\n",
    "            all_relative_values = []\n",
    "            with torch.no_grad():\n",
    "                for (n, p), (oimp_n, oimp), (fimp_n, fimp) in zip(\n",
    "                    self.model.named_parameters(),\n",
    "                    original_importance.items(),\n",
    "                    forget_importance.items(),\n",
    "                ):  \n",
    "\n",
    "                    LAYER_SIZE_CUTOFF = 0 # overrride\n",
    "                    if (p.shape[0]>=LAYER_SIZE_CUTOFF): # only look at large layers\n",
    "\n",
    "                        divs_ = fimp.div(oimp)\n",
    "                        # select only the non nan values of divs_ to avoid errors\n",
    "                        divs_ = divs_[~torch.isnan(divs_)]\n",
    "\n",
    "                        # remove inf\n",
    "                        divs_ = divs_[~torch.isinf(divs_)]\n",
    "                        \n",
    "                        all_relative_values.append(divs_.reshape(-1).cpu().numpy())\n",
    "\n",
    "            all_relative_values = np.concatenate(all_relative_values)  # flatten the array\n",
    "\n",
    "\n",
    "            \n",
    "            #PERCENTILE = 99\n",
    "            print(\"USED Percentile: \", PERCENTILE)\n",
    "            percentile = np.nanpercentile(all_relative_values, PERCENTILE)\n",
    "            \n",
    "            print(\"USED cutoff value: \", percentile)\n",
    "            percentile = percentile.item()\n",
    "\n",
    "        layer_counter = 0\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (n, p), (oimp_n, oimp), (fimp_n, fimp) in zip(\n",
    "                self.model.named_parameters(),\n",
    "                original_importance.items(),\n",
    "                forget_importance.items(),\n",
    "            ):  \n",
    "                layer_counter += 1\n",
    "\n",
    "                # check if p.shape has more than one dimension\n",
    "                if len(p.shape) == 2:\n",
    "                    FULLYCONNECTEDWEIGHTS = True\n",
    "                else:\n",
    "                    FULLYCONNECTEDWEIGHTS = False # then bias layer\n",
    "\n",
    "                #LAYER_SIZE_CUTOFF = 100 # can be added if you want to avoid modifying small layers to increase robustness of the method\n",
    "                if True: #p.shape[0]>=LAYER_SIZE_CUTOFF:\n",
    "\n",
    "                    divs_ = fimp.div(oimp)\n",
    "\n",
    "                    # select only the non nan values of divs_\n",
    "                    divs_ = divs_[~torch.isnan(divs_)]\n",
    "\n",
    "                    #print(fimp, \"XXX\", oimp)\n",
    "                    relative = torch.mean(divs_)\n",
    "                    rel_std = torch.std(divs_)\n",
    "                    rel_median = torch.median(divs_)\n",
    "                    # calculate absolute difference between median and mean\n",
    "                    abs_diff = torch.abs(rel_median - relative)\n",
    "\n",
    "                    if self.alpha == \"Adaptive\":\n",
    "                        #print(relative, 2 * rel_std)\n",
    "                        self.selection_weighting = percentile\n",
    "                    else:\n",
    "                        #print(\"Backup alpha 10\")\n",
    "                        self.selection_weighting = self.alpha\n",
    "\n",
    "                    rel_list.append(self.selection_weighting)\n",
    "                    \n",
    "                    # Synapse Selection with parameter alpha\n",
    "                    oimp_norm = oimp.mul(self.selection_weighting)\n",
    "                    locations = torch.where(fimp > oimp_norm)\n",
    "\n",
    "                    # Synapse Dampening with parameter lambda\n",
    "                    weight = ((oimp.mul(self.dampening_constant)).div(fimp)).pow(\n",
    "                        self.exponent\n",
    "                    )\n",
    "                    update = weight[locations]\n",
    "                    # Bound by 1 to prevent parameter values to increase.\n",
    "                    min_locs = torch.where(update > self.lower_bound)\n",
    "\n",
    "                    # for update take the update value where update > 0.1, otherwise set update 0.1\n",
    "                    # We do not use this in the paper but this can be used to avoid dead nerons for extra robustness\n",
    "                    dampen_limit = DAMPEN_LIMIT\n",
    "                    update[update < dampen_limit] = dampen_limit\n",
    "\n",
    "                    update[min_locs] = self.lower_bound\n",
    "                    p[locations] = p[locations].mul(update)\n",
    "                    \n",
    "        return rel_list\n",
    "\n",
    "\n",
    "def ssd(net, retain_loader, forget_loader, alpha = \"Adaptive\", lambda_param = 0.1):\n",
    "\n",
    "    # ---- SSD to remove memorization of forget data from the network ----\n",
    "    parameters = {\n",
    "        \"dampening_constant\": lambda_param,  # Lambda from paper\n",
    "        \"selection_weighting\": alpha,  # Alpha from paper\n",
    "    }\n",
    "\n",
    "    # SSD forgetting\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "    print(parameters)\n",
    "    pdr = ParameterPerturber(net, optimizer,device=\"mps\", parameters = parameters)\n",
    "    #model = net.eval()\n",
    "\n",
    "    # Calculate the importances of D (see paper)\n",
    "    original_importances = pdr.calc_importance(retain_loader)\n",
    "\n",
    "    # Calculation of the forget set importances\n",
    "    sample_importances = pdr.calc_importance(forget_loader)\n",
    "\n",
    "\n",
    "    # auto select percentile\n",
    "    len_all = len(retain_loader.dataset) + len(forget_loader.dataset)\n",
    "    len_forget = len(forget_loader.dataset)\n",
    "\n",
    "    #share_off = np.sqrt((len_forget/len_all)*100)/MODIFIER_PERCENTILE\n",
    "    share_off = np.log(1 + (len_forget/len_all)*100)\n",
    "\n",
    "    percentile = 100 - share_off\n",
    "    print(\"###### ----- Length based percentile: \", percentile)\n",
    "\n",
    "    # Dampen selected parameters\n",
    "    alpha_list = pdr.modify_weight(original_importances, sample_importances, PERCENTILE = percentile)\n",
    "\n",
    "    return net, alpha_list\n",
    "\n",
    "def get_error_data(X_train_org, y_train_org, MISTAKE_PERCENTAGE, error_scenario = \"both\"):\n",
    "\n",
    "    # create a copy of train data\n",
    "    y_train_mistakes = copy.deepcopy(y_train_org)\n",
    "    X_train_org_change = copy.deepcopy(X_train_org)\n",
    "\n",
    "    # get X% of the data\n",
    "    n = int(len(y_train_mistakes) * MISTAKE_PERCENTAGE/100)\n",
    "\n",
    "    # get a random sample of X% of the data\n",
    "    idx = np.random.choice(len(y_train_mistakes), n, replace=False)\n",
    "\n",
    "    # unused\n",
    "    if CLASSES == 7:\n",
    "        for i in idx:\n",
    "            correct_ = y_train_mistakes[i]\n",
    "            while correct_ == y_train_mistakes[i]:\n",
    "               # random number withing range of CLASSES\n",
    "               y_train_mistakes[i] = np.random.randint(0, CLASSES-1)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # if error_scenario == \"both\" or error_scenario == \"label\":\n",
    "        # Change the values of y_train_mistakes to the opposite value\n",
    "        for i in idx:\n",
    "            #org_y = y_train_mistakes[i] \n",
    "            if y_train_mistakes[i] == 0:\n",
    "                y_train_mistakes[i] = np.random.choice([1, 2]) \n",
    "            if y_train_mistakes[i] == 1:\n",
    "                y_train_mistakes[i] = np.random.choice([0, 2])  \n",
    "            if y_train_mistakes[i] == 2:\n",
    "                y_train_mistakes[i] = np.random.choice([0, 1])  \n",
    "\n",
    "    # save the non idx rows from X_train as X_train_retain and idx rows as y_train_forget\n",
    "    X_train_retain = X_train_org_change.drop(idx)\n",
    "    y_train_retain = y_train_mistakes.drop(idx)\n",
    "\n",
    "    X_train_forget = X_train_org_change.iloc[idx]\n",
    "    y_train_forget = y_train_mistakes.iloc[idx]\n",
    "\n",
    "    return X_train_retain, y_train_retain, X_train_forget, y_train_forget, y_train_mistakes\n",
    "\n",
    "def train_model(model, trial, DEVICE, X, Y, BATCHSIZE, EPOCHS, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES, X_test, y_test_class, optuna = True, use_existing_model = False, ft_lr = None, lr = None, l2_pen = None):\n",
    "\n",
    "    if use_existing_model == True:\n",
    "        lr = ft_lr\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=l2_pen)\n",
    "    #optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the custom dataset.\n",
    "    # split X_train and y_train_class into train and validation sets\n",
    "    X_Train, X_Val, y_Train_class, y_Val_class = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if optuna == False: # use full dataset for training\n",
    "        X_Train = X\n",
    "        y_Train_class = Y\n",
    "\n",
    "    train_loader = get_custom_dataset(X_Train, y_Train_class)\n",
    "    valid_loader = get_custom_dataset(X_Val, y_Val_class)\n",
    "\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma_)\n",
    "\n",
    "    # early stopping (since we reduce the training size by having error data that we take out for retraining)\n",
    "    best_loss = float('inf')\n",
    "    patience = 10000000  # Number of epochs to wait for improvement\n",
    "    counter = 0  # Counter to keep track of epochs without improvement\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                valid_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        valid_loss /= min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        # Check if the validation loss has improved\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        # Check if early stopping condition is met\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "        \n",
    "    \n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "        \n",
    "    # Make predictions\n",
    "    y_pred = model(torch.tensor(X_test.values, dtype=torch.float32).to(DEVICE))\n",
    "    y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "\n",
    "    # Evaluate the model accuracy\n",
    "    acc = accuracy_score(y_test_class, y_pred)\n",
    "\n",
    "    return model, acc * 100\n",
    "\n",
    "\n",
    "def get_plots(results, RUN_NAME, prefix = \"\", delta = False):\n",
    "\n",
    "    # print the share of runs where SSD is better than Mistake\n",
    "    print(\"Share of runs where SSD is BETTER than Mistake: {:.2f}%\".format(len(results[results['SSD'] > results['Mistake']])/len(results) * 1))\n",
    "    print(\"Share of runs where SSD is EQUAL to Mistake: {:.2f}%\".format(len(results[results['SSD'] == results['Mistake']])/len(results) * 1))\n",
    "    print(\"Share of runs where SSD is WORSE than Mistake: {:.2f}%\".format(len(results[results['SSD'] < results['Mistake']])/len(results) * 1))\n",
    "\n",
    "    if delta:\n",
    "        results[\"SSD\"] = results[\"SSD\"] - results[\"Mistake\"]\n",
    "        results[\"Best\"] = results[\"Best\"] - results[\"Mistake\"]\n",
    "        results[\"Mistake\"] = results[\"Mistake\"]*0\n",
    "        prefix += \"_delta_\"\n",
    "\n",
    "    results= results.apply(pd.to_numeric, errors='coerce')\n",
    "    # Create a boxplot for the three columns\n",
    "    plt.figure(figsize=(6, 8))  # Adjust the figure size if needed\n",
    "\n",
    "    results.boxplot(column=['Mistake', 'SSD', \"Best\"], showmeans=True)\n",
    "    #results.boxplot(column=['Mistake', 'SSD', 'ft_Mistake', 'ft_SSD', \"Best\"], showmeans=True)\n",
    "    # remove gridlines\n",
    "    plt.grid(False)\n",
    "\n",
    "    # shade each box in a different color\n",
    "    colors = ['blue', 'orange', 'green']\n",
    "    for patch, color in zip(plt.gca().patches, colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    # add custom names for the three boxes\n",
    "    plt.gca().set_xticklabels([\"Baseline\", 'SSD', \"Retrained\"])\n",
    "    #plt.gca().set_xticklabels([\"Baseline\", 'SSD', 'Baseline+FT', 'SSD+FT', \"Retrained\"])\n",
    "\n",
    "    plt.title('Model accuracy relative to baseline model trained on data with errors')\n",
    "    plt.ylabel('Accuracy gain/loss in percentage points')\n",
    "\n",
    "    # save the plot as a svg file in results/RUN_NAME\n",
    "    plt.savefig(FOLDER_PREFIX+'results/' + prefix + RUN_NAME + '_plot.png', format='png')\n",
    "\n",
    "\n",
    "    # --- Detail plot ---\n",
    "\n",
    "    results= results.apply(pd.to_numeric, errors='coerce')\n",
    "    # Create a boxplot for the three columns\n",
    "    plt.figure(figsize=(4, 4))  # Adjust the figure size if needed\n",
    "    results.boxplot(column=['Add corr classifications'], showmeans=True)\n",
    "    # remove gridlines\n",
    "    plt.grid(False)\n",
    "\n",
    "    # shade each box in a different color\n",
    "    colors = ['blue', 'orange', 'green']\n",
    "    for patch, color in zip(plt.gca().patches, colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    # add custom names for the three boxes\n",
    "    plt.gca().set_xticklabels(['Performance gain from unlearning'])\n",
    "\n",
    "    # plot a horizontal line at 0\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "\n",
    "    #plt.ylim(-0.01, 0.01)\n",
    "\n",
    "    plt.title('Model improvement after unlearning')\n",
    "    plt.ylabel('Additional correct classifications')\n",
    "    \n",
    "    # save the plot as a svg file in results/RUN_NAME\n",
    "    plt.savefig(FOLDER_PREFIX+'results/' + prefix +'_detail_' + RUN_NAME + '_plot.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and prep (train/test/preprocessing)\n",
    "\n",
    "if SKIP_DATA_LOADING == False:\n",
    "    df =pd.read_csv('data/DataCoSupplyChainDataset.csv',encoding='latin-1')\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    # add a new label column of sipping delay\n",
    "    df['delay'] = df['Days for shipping (real)'] - df['Days for shipment (scheduled)']\n",
    "\n",
    "    # drop the redundant label columns\n",
    "    df = df.drop(['Days for shipping (real)'],axis=1)\n",
    "\n",
    "    # Time index\n",
    "    df[\"shipping date (DateOrders)\"] = pd.to_datetime(df[\"shipping date (DateOrders)\"])\n",
    "\n",
    "    df[\"time_idx\"] = df[\"shipping date (DateOrders)\"].dt.day * 1 + df[\"shipping date (DateOrders)\"].dt.year * 365 + df[\"shipping date (DateOrders)\"].dt.month * 31\n",
    "    df[\"time_idx\"] -= df[\"time_idx\"].min()\n",
    "\n",
    "    # Only use completed or closed orders\n",
    "    print(\"All orders: \", df.shape)\n",
    "    df = df[df['Order Status'] == 'COMPLETE']\n",
    "    print(\"Completed orders: \", df.shape)\n",
    "\n",
    "    # ------------------ Data Preprocessing ------------------\n",
    "\n",
    "    # Reduction to a few features for POC\n",
    "\n",
    "    # Select features from a list of strings\n",
    "    feature_list = list()\n",
    "\n",
    "    # add all column names to the list\n",
    "    for column in df.columns:\n",
    "        feature_list.append(column)\n",
    "\n",
    "    # remove the columns that are not needed\n",
    "    feature_list.remove('Days for shipment (scheduled)')\n",
    "    feature_list.remove('Delivery Status')\n",
    "    feature_list.remove('Order Item Cardprod Id')\n",
    "    feature_list.remove('Order Item Id')\n",
    "    feature_list.remove('Order Id')\n",
    "\n",
    "    # create a list of categorical features by removing all others\n",
    "    # copy the feature list\n",
    "    categorical_features = feature_list.copy()\n",
    "\n",
    "    categorical_features.remove('time_idx')\n",
    "    categorical_features.remove('delay')\n",
    "    categorical_features.remove('Benefit per order')\n",
    "    categorical_features.remove('Sales per customer')\n",
    "    categorical_features.remove('Latitude')\n",
    "    categorical_features.remove('Longitude')\n",
    "    categorical_features.remove('Order Item Total')\n",
    "    categorical_features.remove('Order Item Discount')\n",
    "    categorical_features.remove('Order Item Product Price')\n",
    "    categorical_features.remove('Product Price')\n",
    "    categorical_features.remove('Order Item Quantity')\n",
    "    categorical_features.remove('Order Item Profit Ratio')\n",
    "    categorical_features.remove('Order Profit Per Order')\n",
    "\n",
    "    # only keep the features in the list\n",
    "    df_poc = df[feature_list]\n",
    "\n",
    "    # one hot encode all features in the categorical_features list\n",
    "    all_ = len(categorical_features)\n",
    "    i = 0\n",
    "    for feature in categorical_features:\n",
    "        i += 1\n",
    "\n",
    "        # check if it would create more than 10000 new features\n",
    "        if len(df_poc[feature].unique()) > 1000:\n",
    "            print(\"Feature: \", feature, \" has too many unique values (\", len(df_poc[feature].unique()), \")\")\n",
    "            \n",
    "            # drop the feature\n",
    "            df_poc = df_poc.drop([feature], axis=1)\n",
    "        else:\n",
    "            print(\"Encoding feature: \", feature, \" (\", i, \"/\", all_, \")\")\n",
    "            df_poc = pd.get_dummies(df_poc, columns=[feature])\n",
    "\n",
    "\n",
    "    # show all df columns\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    print(\"Preprocessed: \", df_poc.shape)\n",
    "\n",
    "    # ------------------ Data Splitting ------------------\n",
    "\n",
    "    # Split the data into train and test with test being the last 20% of the data based on time_idx\n",
    "    df_poc = df_poc.sort_values(\"time_idx\").reset_index(drop=True)\n",
    "\n",
    "    test_size = int(len(df_poc) * TEST_PERCENTAGE/100)\n",
    "    train_df = df_poc[:-test_size]\n",
    "    test_df = df_poc[-test_size:]\n",
    "\n",
    "    # split into X and y\n",
    "    X_train = train_df.drop([\"delay\"], axis=1)\n",
    "    y_train = train_df[\"delay\"]\n",
    "\n",
    "    X_test = test_df.drop([\"delay\"], axis=1)\n",
    "    y_test = test_df[\"delay\"]\n",
    "\n",
    "    # ------------------ Data Normalization ------------------\n",
    "\n",
    "    # Normalize the data for neural network use fitting on X_train and applying to X_test\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Keep as datafames\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    print(\"Pre feature selection: \")\n",
    "    print(\"X_train: \", X_train.shape)\n",
    "    print(\"X_test: \", X_test.shape)\n",
    "\n",
    "    # ------------------ Simple feature selection  ------------------\n",
    "\n",
    "    print(\"After feature selection: \")\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "    # set it to hit ca. 100 features\n",
    "    var_limit = 0.12345\n",
    "    sel = VarianceThreshold(var_limit)\n",
    "\n",
    "    # fit and transform on train and add column names of remaining columns as a dataframe\n",
    "    X_train = pd.DataFrame(sel.fit_transform(X_train), columns=X_train.columns[sel.get_support()])\n",
    "    X_test = pd.DataFrame(sel.transform(X_test), columns=X_test.columns[sel.get_support()])\n",
    "\n",
    "\n",
    "    # ------------------ Data Preparation: Classes ------------------\n",
    "\n",
    "    # We do this as a class prediction problem\n",
    "    # for y_train and y_test we put all delays that are below 0 into one class and all other delays into a class corresponding to the delay +1 up to a max delay of 4 days\n",
    "\n",
    "    # create a new column with the class labels\n",
    "\n",
    "    # simplify to just early, late, on time\n",
    "    if CLASSES == 3:\n",
    "        # Train\n",
    "        y_train_class = y_train.copy()\n",
    "        y_train_class[y_train < 0] = 0\n",
    "        y_train_class[y_train == 0] = 1\n",
    "        y_train_class[y_train >= 1] = 2\n",
    "\n",
    "\n",
    "\n",
    "        # Test\n",
    "        y_test_class = y_test.copy()\n",
    "        y_test_class[y_test < 0] = 0\n",
    "        y_test_class[y_test == 0] = 1\n",
    "        y_test_class[y_test >= 1] = 2\n",
    "    else:\n",
    "        print(\"not designed for other cases, set value to 3 classes\")\n",
    "\n",
    "    print(\"X_train: \", X_train.shape)\n",
    "    print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print how much of the train set a certain percentage is in samples\n",
    "\n",
    "n_train = len(y_train_class)\n",
    "print(\"Number of samples in train set: \", n_train)\n",
    "\n",
    "# test\n",
    "print(\"Number of samples in test set: \", len(y_test_class))\n",
    "\n",
    "# share of test set compared to train plus test\n",
    "print(\"Share of test set: {:.2f}%\".format(len(y_test_class)/(len(y_test_class) + n_train) * 100))\n",
    "\n",
    "precentages_ = [5, 1, 0.5, 0.25, 0.025]\n",
    "\n",
    "for percentage in precentages_:\n",
    "    n_samples = int(n_train * percentage/100)\n",
    "    print(\"Number of samples in train set for \", percentage, \"%: \", n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram for the three classes in y_train and y_test\n",
    "\n",
    "# Plotting histogram for y_train\n",
    "train_classes, train_counts = np.unique(y_train_class, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(train_classes, train_counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Classes in y_train')\n",
    "plt.show()\n",
    "\n",
    "# Plotting histogram for y_test\n",
    "test_classes, test_counts = np.unique(y_test_class, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(test_classes, test_counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Classes in y_test')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselines (XGB, naive)\n",
    "\n",
    "if SKIP_DATA_LOADING == False: # no need to rerun with same data\n",
    "    # XGB classification model\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "    xgb_model.fit(X_train, y_train_class)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_class, y_pred))\n",
    "    xgb_accuracy = accuracy_score(y_test_class, y_pred)\n",
    "\n",
    "\n",
    "    # Naive baseline\n",
    "    y_pred = np.ones(len(y_test_class)) *  y_test_class.value_counts().index[0] # majority class\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_class, y_pred))\n",
    "\n",
    "    naive_accuracy = accuracy_score(y_test_class, y_pred)\n",
    "    \n",
    "print(\"XGB baseline accuracy: {:.2f}%\".format(xgb_accuracy * 100))\n",
    "print(\"Naive baseline accuracy: {:.2f}%\".format(naive_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN parameter optimization (Optuna)\n",
    "\n",
    "if SKIP_OPTUNA == False:\n",
    "    # convert boolean columns to scalar for NN\n",
    "    X_train = convert_boolean_to_int(X_train)\n",
    "    X_test = convert_boolean_to_int(X_test)\n",
    "\n",
    "    X_train_retain, y_train_retain, X_train_forget, y_train_forget, y_train_mistakes = get_error_data(X_train, y_train_class, MISTAKE_PERCENTAGE)\n",
    "\n",
    "    DEVICE = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")  # Use \"metal\" if available, otherwise \"cpu\"\n",
    "    DIR = os.getcwd()\n",
    "    #EPOCHS = 10\n",
    "    N_TRAIN_EXAMPLES = BATCHSIZE * 100000000 # unlimited\n",
    "    N_VALID_EXAMPLES = BATCHSIZE * 100000000\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=N_TRIALS, timeout=600, callbacks=[callback])\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    clear_output()\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    best_trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", best_trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    full_data_acc = best_trial.value * 100\n",
    "\n",
    "# get epochs from trial object\n",
    "EPOCHS = best_trial.params[\"epochs\"]\n",
    "\n",
    "# deepcopy best_trial as trial\n",
    "use_trial = copy.deepcopy(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final lr\n",
    "print(\"Starting lr: \", use_trial.params[\"lr\"])\n",
    "lr = use_trial.params[\"lr\"]\n",
    "final_lr = lr * gamma_ ** EPOCHS\n",
    "print(\"Final lr: \", final_lr)\n",
    "\n",
    "# going one further for finetuning\n",
    "ft_lr = final_lr * gamma_\n",
    "print(\"Finetuning lr: \", ft_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the model parameters from Optuna here and pass them as dict to the training:\n",
    "MODEL_base = define_model(use_trial).to(DEVICE)\n",
    "LR = use_trial.params[\"lr\"]\n",
    "L2_PEN = use_trial.params[\"l2_pen\"]\n",
    "\n",
    "\n",
    "def run_experiment(RUN_NAME):\n",
    "\n",
    "    # Logging: dataframe with columns SSD, Mistake, Best and 10 rows filled with nan\n",
    "    results = pd.DataFrame(columns=['SSD', 'Mistake', 'Best', \"ft_SSD\", \"ft_Mistake\" ], index=range(ITERATIONS))\n",
    "    results_raw = pd.DataFrame(columns=['SSD', 'Mistake', 'Best', \"ft_SSD\", \"ft_Mistake\", \"rt_Best\", \"rt_SSD\", \"rt_Mistake\", \"ft_rt_SSD\", \"ft_rt_Mistake\"], index=range(ITERATIONS))\n",
    "\n",
    "    # create a dictionary to collect lists of alphas\n",
    "    alpha_dict = dict()\n",
    "\n",
    "    for run_i in range(ITERATIONS):\n",
    "        # set random seeds for random, numpy and torch\n",
    "        SEED = run_i\n",
    "        np.random.seed(SEED)\n",
    "        torch.manual_seed(SEED)\n",
    "        random.seed(SEED)\n",
    "        sampler = TPESampler(seed=SEED) \n",
    "\n",
    "        clear_output() # done here to leave the print statements out for longer to read\n",
    "\n",
    "        print(results)\n",
    "        # print the mean of the results dataframe\n",
    "        print(\"Mean: \")\n",
    "        print(results.mean())\n",
    "\n",
    "        print(\"Median: \")\n",
    "        print(results.median())\n",
    "\n",
    "        # print the raw mean and median\n",
    "        print(\"Raw Mean: \")\n",
    "        print(results_raw.mean())\n",
    "\n",
    "        print(\"Raw Median: \")\n",
    "        print(results_raw.median())\n",
    "\n",
    "        print(RUN_NAME, \"Starting Iteration: \", run_i+1, \"/\", ITERATIONS)\n",
    "\n",
    "        # ---------------- Add errors to the data ----------------\n",
    "        X_train_retain, y_train_retain, X_train_forget, y_train_forget, y_train_mistakes = get_error_data(X_train, y_train_class, MISTAKE_PERCENTAGE, error_scenario = ERROR_SCENARIO)\n",
    "\n",
    "        wrong_share = (len(y_train_forget)/(len(y_train_forget) + len(y_train_retain)))*100\n",
    "        print(\"Share of wrong labels: {:.2f}%\".format(wrong_share))\n",
    "        # in abslute numbers\n",
    "        print(\"Number of wrong labels: \", len(y_train_forget))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # ---------------- Train the mistake model ----------------\n",
    "\n",
    "        # Train a neural network with the best hyperparameters we determined on the data with mistakes\n",
    "        model = []\n",
    "        MODEL = copy.deepcopy(MODEL_base)\n",
    "        trial = []\n",
    "        mistake_model, mistake_accuracy = train_model(MODEL, trial, DEVICE, X_train, y_train_mistakes, \n",
    "                                        BATCHSIZE, EPOCHS, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES, X_test, y_test_class, optuna=False, lr=LR, l2_pen=L2_PEN)\n",
    "        \n",
    "\n",
    "        # get model accuracy on the retain data\n",
    "        y_pred = mistake_model(torch.tensor(X_train_retain.values, dtype=torch.float32).to(DEVICE))\n",
    "        y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "        rt_mistake_accuracy = accuracy_score(y_train_retain, y_pred)\n",
    "        \n",
    "        mistake_save_model = copy.deepcopy(mistake_model)\n",
    "        # Alternatively add one epoch of retraining\n",
    "        if fine_tune_on:\n",
    "            trial = copy.deepcopy(best_trial)\n",
    "            ft_mistake_model, ft_mistake_accuracy = train_model(mistake_model, trial, DEVICE, X_train_retain, y_train_retain, \n",
    "                                            BATCHSIZE, 1, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES, X_test, y_test_class, optuna=False, use_existing_model = True, ft_lr = ft_lr, lr=LR, l2_pen=L2_PEN)\n",
    "\n",
    "        # get model accuracy on the retain data\n",
    "        y_pred = ft_mistake_model(torch.tensor(X_train_retain.values, dtype=torch.float32).to(DEVICE))\n",
    "        y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "        ft_rt_mistake_accuracy = accuracy_score(y_train_retain, y_pred)\n",
    "\n",
    "        # ---------------- Perform unlearning ----------------\n",
    "\n",
    "        ssd_model = copy.deepcopy(mistake_save_model)\n",
    "        ssd_model.to(DEVICE)\n",
    "\n",
    "        retain = get_custom_dataset(X_train_retain, y_train_retain)\n",
    "        forget = get_custom_dataset(X_train_forget, y_train_forget)\n",
    "\n",
    "        \n",
    "        # Start the time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        _, alph_list = ssd(ssd_model, retain, forget, alpha=ALPHA, lambda_param=LAMBDA_PARAM)\n",
    "\n",
    "        # Record the end time\n",
    "        end_time = time.time()\n",
    "\n",
    "        # add alph_list list to alpha_dict with index of the iteration\n",
    "        alpha_dict[run_i] = alph_list\n",
    "\n",
    "        # Make predictions\n",
    "        ssd_model.to(DEVICE)\n",
    "\n",
    "        # REAL LIFE SAFETY STEP (not used in the paper but can be used in real life for extra robustness)\n",
    "        # Test on retain data if we think this model should be favoured:\n",
    "        y_pred = ssd_model(torch.tensor(X_train_retain.values, dtype=torch.float32).to(DEVICE))\n",
    "        y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "        ssd_expected_accuracy = accuracy_score(y_train_retain, y_pred)\n",
    "\n",
    "        y_pred = mistake_model(torch.tensor(X_train_retain.values, dtype=torch.float32).to(DEVICE))\n",
    "        y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "        mistake_expected_accuracy = accuracy_score(y_train_retain, y_pred)\n",
    "\n",
    "\n",
    "        # Calculate the elapsed time\n",
    "        elapsed_time = end_time - start_time\n",
    "       \n",
    "\n",
    "        if ssd_expected_accuracy > mistake_expected_accuracy * TOLERANCE:\n",
    "            y_pred = ssd_model(torch.tensor(X_test.values, dtype=torch.float32).to(DEVICE))\n",
    "            y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "\n",
    "            # Evaluate the model accuracy\n",
    "            ssd_accuracy = accuracy_score(y_test_class, y_pred)\n",
    "        else:\n",
    "            ssd_accuracy = mistake_accuracy/100\n",
    "        \n",
    "        ssd_accuracy = ssd_accuracy * 100 # already done for other trainings in the train_model function\n",
    "\n",
    "\n",
    "        # get model accuracy on the retain data\n",
    "        y_pred = ssd_model(torch.tensor(X_train_retain.values, dtype=torch.float32).to(DEVICE))\n",
    "        y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "        rt_ssd_accuracy = accuracy_score(y_train_retain, y_pred)\n",
    "\n",
    "        # Alternatively add one epoch of retraining\n",
    "        if fine_tune_on:\n",
    "            trial = copy.deepcopy(best_trial)\n",
    "            ft_ssd_model, ft_ssd_accuracy = train_model(ssd_model, trial, DEVICE, X_train_retain, y_train_retain, \n",
    "                                            BATCHSIZE, 1, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES, X_test, y_test_class, optuna=False, use_existing_model = True, ft_lr = ft_lr, lr=LR, l2_pen=L2_PEN)\n",
    "\n",
    "        # get model accuracy on the retain data\n",
    "        y_pred = ft_ssd_model(torch.tensor(X_train_retain.values, dtype=torch.float32).to(DEVICE))\n",
    "        y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "        ft_rt_ssd_accuracy = accuracy_score(y_train_retain, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------- Train the correct model ----------------\n",
    "\n",
    "        # Train a neural network with the best hyperparameters we determined on the data without mistakes\n",
    "        \n",
    "        model = []\n",
    "        MODEL = copy.deepcopy(MODEL_base)\n",
    "        trial = []\n",
    "        #  on correct data\n",
    "        best_model, best_accuracy = train_model(MODEL, trial, DEVICE, X_train_retain, y_train_retain, \n",
    "                                        BATCHSIZE, EPOCHS, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES, X_test, y_test_class, optuna=False, lr=LR, l2_pen=L2_PEN)\n",
    "        \n",
    "        # get model accuracy on the retain data\n",
    "        y_pred = best_model(torch.tensor(X_train_retain.values, dtype=torch.float32).to(DEVICE))\n",
    "        y_pred = y_pred.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "        rt_best_accuracy = accuracy_score(y_train_retain, y_pred)\n",
    "\n",
    "        # Add everything to the logging dataframe\n",
    "        results_raw.loc[run_i, 'SSD'] = ssd_accuracy\n",
    "        results_raw.loc[run_i, 'Mistake'] = mistake_accuracy\n",
    "        results_raw.loc[run_i, 'Best'] = best_accuracy\n",
    "\n",
    "        results_raw.loc[run_i, 'rt_SSD'] = rt_ssd_accuracy * 100\n",
    "        results_raw.loc[run_i, 'rt_Mistake'] = rt_mistake_accuracy * 100\n",
    "        results_raw.loc[run_i, 'rt_Best'] = rt_best_accuracy * 100\n",
    "        results_raw.loc[run_i, 'ft_rt_SSD'] = ft_rt_ssd_accuracy * 100\n",
    "        results_raw.loc[run_i, 'ft_rt_Mistake'] = ft_rt_mistake_accuracy * 100\n",
    "\n",
    "        results_raw.loc[run_i, 'ft_SSD'] = ft_ssd_accuracy\n",
    "        results_raw.loc[run_i, 'ft_Mistake'] = ft_mistake_accuracy\n",
    "\n",
    "        \n",
    "        if True: # Make it all relative to the performance of the mistake model\n",
    "            results.loc[run_i, 'SSD'] = ssd_accuracy - mistake_accuracy\n",
    "            results.loc[run_i, 'Best'] = best_accuracy - mistake_accuracy\n",
    "            results.loc[run_i, 'Mistake'] = mistake_accuracy * 0\n",
    "\n",
    "            results.loc[run_i, 'ft_SSD'] = ft_ssd_accuracy - mistake_accuracy\n",
    "            results.loc[run_i, 'ft_Mistake'] = ft_mistake_accuracy - mistake_accuracy\n",
    "        else:\n",
    "            results.loc[run_i, 'SSD'] = ssd_accuracy\n",
    "            results.loc[run_i, 'Best'] = best_accuracy\n",
    "            results.loc[run_i, 'Mistake'] = mistake_accuracy\n",
    "\n",
    "            results.loc[run_i, 'ft_SSD'] = ft_ssd_accuracy\n",
    "            results.loc[run_i, 'ft_Mistake'] = ft_mistake_accuracy\n",
    "\n",
    "\n",
    "        # Call clear_output() to clear the output of the current cell\n",
    "        print(f\"SSD Elapsed time: {elapsed_time} seconds\")\n",
    "        #print(\"ALPHA: \", ALPHA)\n",
    "        \n",
    "        print(RUN_NAME, \"Iteration: \", run_i+1, \"/\", ITERATIONS)\n",
    "        print(results)\n",
    "\n",
    "        # print the mean of the results dataframe\n",
    "        print(\"Mean: \")\n",
    "        print(results.mean())\n",
    "\n",
    "        print(\"Median: \")\n",
    "        print(results.median())\n",
    "\n",
    "        # print the raw mean and median\n",
    "        print(\"Raw Mean: \")\n",
    "        print(results_raw.mean())\n",
    "\n",
    "        print(\"Raw Median: \")\n",
    "        print(results_raw.median())\n",
    "\n",
    "    # ------------------ Calculating additional columns ------------------\n",
    "    # multiply each column by 100 for percentage\n",
    "    results = results #* 100\n",
    "\n",
    "    results[\"Delta to Best\"] = (results[\"Mistake\"] - results[\"Best\"])\n",
    "    results[\"Gain\"] = (results[\"SSD\"] - results[\"Mistake\"])/results[\"Mistake\"] * 100\n",
    "\n",
    "    results[\"Base Gap\"] = results[\"Mistake\"] -results[\"Best\"] \n",
    "    results[\"SSD Gap\"] =  results[\"SSD\"] - results[\"Best\"] \n",
    "\n",
    "    # number of samples in test data\n",
    "    n = len(y_test_class)\n",
    "\n",
    "    print(\"total test cases: \", n)\n",
    "\n",
    "    # ------------------ Same for raw (put in a loop in the future) ------------------\n",
    "    # multiply each column by 100 for percentage\n",
    "    results_raw = results_raw #* 100\n",
    "\n",
    "    results_raw[\"Delta to Best\"] = (results_raw[\"Mistake\"] - results_raw[\"Best\"])\n",
    "    results_raw[\"Gain\"] = (results_raw[\"SSD\"] - results_raw[\"Mistake\"])/results_raw[\"Mistake\"] * 100\n",
    "\n",
    "    results_raw[\"Base Gap\"] = results_raw[\"Mistake\"] -results_raw[\"Best\"] \n",
    "    results_raw[\"SSD Gap\"] =  results_raw[\"SSD\"] - results_raw[\"Best\"] \n",
    "\n",
    "    # number of samples in test data\n",
    "    n = len(y_test_class)\n",
    "\n",
    "    print(\"total test cases: \", n)\n",
    "    results_raw[\"Add corr classifications\"] = n * results_raw[\"Gain\"] / 100\n",
    "    results_raw[\"Num gap to best\"] = -n * results_raw[\"Base Gap\"] / 100\n",
    "    # cut off the decimal places\n",
    "    results_raw[\"Add corr classifications\"] = results_raw[\"Add corr classifications\"].astype(int)\n",
    "    results_raw[\"Num gap to best\"] = results_raw[\"Num gap to best\"].astype(int)\n",
    "\n",
    "    results_raw[\"Gap closed\"] = results_raw[\"Add corr classifications\"]/results_raw[\"Num gap to best\"] * 100\n",
    "\n",
    "    # copy in\n",
    "    results[\"Add corr classifications\"] =  results_raw[\"Add corr classifications\"]\n",
    "    results[\"Num gap to best\"] =  results_raw[\"Num gap to best\"]\n",
    "    results[\"Gap closed\"] =  results_raw[\"Gap closed\"]\n",
    "    # ------------------ Summary ------------------\n",
    "    # create a new dataframe with the same column names and first row mean of the results dataframe, second row std of the results dataframe\n",
    "    summary = pd.DataFrame(columns=results.columns, index=['mean', 'std'])\n",
    "\n",
    "    # fill the first row with the mean of the results dataframe\n",
    "    summary.loc['mean'] = results.mean()\n",
    "    summary.loc['median'] = results.median()\n",
    "\n",
    "    # fill the second row with the std of the results dataframe\n",
    "    summary.loc['std'] = results.std()\n",
    "\n",
    "    clear_output()\n",
    "    \n",
    "    get_plots(results, RUN_NAME)\n",
    "    get_plots(results, RUN_NAME, delta=True)\n",
    "\n",
    "    # save the results dataframe to csv using the name from the variable RUN_NAME\n",
    "    results.to_csv(FOLDER_PREFIX+'results/log_' + RUN_NAME + '.csv')\n",
    "    results_raw.to_csv(FOLDER_PREFIX+'results/log_raw_' + RUN_NAME + '.csv')\n",
    "\n",
    "    # hacky modification to get the same plot on the retain set\n",
    "    if True:\n",
    "        results_raw[\"Mistake\"] = results_raw[\"rt_Mistake\"]\n",
    "        results_raw[\"Best\"] = results_raw[\"rt_Best\"]\n",
    "        results_raw[\"ft_Mistake\"] = results_raw[\"ft_rt_Mistake\"]\n",
    "        results_raw[\"SSD\"] = results_raw[\"rt_SSD\"]\n",
    "        results_raw[\"ft_SSD\"] = results_raw[\"ft_rt_SSD\"]\n",
    "\n",
    "    get_plots(results_raw, RUN_NAME, prefix = \"rt_\")\n",
    "    get_plots(results, RUN_NAME, prefix = \"rt_\", delta=True)\n",
    "\n",
    "    summary.head()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_sig_check(results_list, name_list):\n",
    "\n",
    "    for results, name_ in zip(results_list, name_list):\n",
    "        # Perform an independent samples t-test\n",
    "        column1_data = pd.to_numeric(results['SSD'], errors='coerce') \n",
    "        column2_data = pd.to_numeric(results['Mistake'], errors='coerce') \n",
    "\n",
    "        t_statistic, p_value = stats.ttest_ind(column1_data, column2_data)\n",
    "\n",
    "        # Output the results\n",
    "        print(f'T-Statistic: {t_statistic}')\n",
    "        print(f'P-Value: {p_value}')\n",
    "\n",
    "        # Interpret the results\n",
    "        alpha = 0.05  # Set your significance level (e.g., 0.05)\n",
    "        print(\"RUN: \", name_)\n",
    "        \n",
    "        if p_value < alpha:\n",
    "            print(\"Reject the null hypothesis: There is a significant difference between the two columns.\")\n",
    "            return \"Significant\"\n",
    "        else:\n",
    "            print(\"Fail to reject the null hypothesis: There is no significant difference between the two columns.\")\n",
    "            return \"NOT Significant\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and save experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get error data for the baseline\n",
    "X_train_retain, y_train_retain, X_train_forget, y_train_forget, y_train_mistakes = get_error_data(X_train, y_train_class, MISTAKE_PERCENTAGE, error_scenario = ERROR_SCENARIO)\n",
    "\n",
    "# print shape of each\n",
    "print(\"X_train_retain: \", X_train_retain.shape)\n",
    "print(\"y_train_retain: \", y_train_retain.shape)\n",
    "print(\"X_train_forget: \", X_train_forget.shape)\n",
    "print(\"y_train_forget: \", y_train_forget.shape)\n",
    "print(\"y_train_mistakes: \", y_train_mistakes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 3\n",
    "\n",
    "fine_tune_on = True\n",
    "mistake_percentages = [0.5, 1, 2.5, 5, 7.5, 10, 0.025, 0.25]\n",
    "lambda_params = [1]\n",
    "dampen_limits = [0]\n",
    "tolerances = [0]\n",
    "alphas = [\"Adaptive\"]\n",
    "\n",
    "LAYER_SIZE_CUTOFF = 1 # 1 does nothing, could set higher to ignore layers with less than x parameters\n",
    "\n",
    "total_iterations = len(mistake_percentages) * len(lambda_params) * len(dampen_limits) * len(tolerances) * len(alphas)\n",
    "\n",
    "results_list = list()\n",
    "name_list = list()\n",
    "\n",
    "\n",
    "for MISTAKE_PERCENTAGE in mistake_percentages:\n",
    "    for LAMBDA_PARAM in lambda_params:\n",
    "        for DAMPEN_LIMIT in dampen_limits:\n",
    "            for TOLERANCE in tolerances:\n",
    "                for ALPHA in alphas:\n",
    "\n",
    "                    # Combine the parameters into a run name string\n",
    "                    RUN_NAME = f\"{MISTAKE_PERCENTAGE}perc_a{ALPHA}_lam{LAMBDA_PARAM}_tol{TOLERANCE}_damplim{DAMPEN_LIMIT}\"\n",
    "                    #print(RUN_NAME)\n",
    "                    results = run_experiment(RUN_NAME)\n",
    "                    results_list.append(results)\n",
    "                    name_list.append(RUN_NAME)\n",
    "\n",
    "                    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlearn_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
